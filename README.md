
# ðŸš¨ Risk Behavior Detection System for Drivers

This project uses **YOLOv5, YOLOv8, YOLOv11, and YOLOv12** (compatible formats: `.pt` [PyTorch], `.tflite` [TensorFlow Lite float32, float16, int8, and EdgeTPU]), along with **MediaPipe**, **Dlib**, and **OpenCV** to detect dangerous driver behaviors such as:

- Drowsiness  
- Mobile phone usage  
- No seatbelt  
- Excessive body leaning  
- Smoking  

âš ï¸ When suspicious behavior is detected, an **audible alert** is automatically triggered.

---

## âœ… Features

- Object detection using **YOLO** (`drowsy`, `phone`, `smoking`, `seatbelt`, `awake`)
- **Eye closure detection** using Dlib (facial landmarks and Blink Ratio â€” BR)
- **Posture analysis** using MediaPipe (calculating Nose-to-Shoulder Center ratio â€” DSC)
- **Automatic audible alert** using `playsound`
- Real-time interface with **OpenCV**

---

## ðŸ§° Requirements

### Python Libraries

Clone the repository:

```bash
git clone https://github.com/HyAgOsK/Drowsy_detection.git
cd Drowsy_detection/
```

Create and activate a virtual environment (recommended for Raspberry Pi 4/5):

```bash
python -m venv venv
source venv/bin/activate
```

Install dependencies:

```bash
pip install -r requirements.txt
```

Active the default performace EdgeTPU Coral USB

```bash
silvatpu-linux-setup
```

Activate the `max` performace of EdgeTPU Coral USB

```bash
silvatpu-linux-setup --speed max

```

> âš ï¸ **Note:** Installing `dlib` requires **CMake** and a compatible C++ compiler.
> 
### Other Prerequisites

- Python 3.8 or higher  
- Coral EdgeTPU (optional, for model acceleration)  
- Webcam or video file  
- Required files:
  - `shape_predictor_68_face_landmarks.dat` (Dlib facial landmark model)
  - `alarm.wav` (alert sound)
  - Trained YOLO model (`best.pt`) .pt .tflite
  - YOLO tracking configuration file: `botsort.yaml` (if using `track()`)

---

## ðŸ—‚ï¸ Expected Folder Structure

```
project/
â”‚
â”œâ”€â”€ alarm.wav
â”œâ”€â”€ shape_predictor_68_face_landmarks.dat
â”œâ”€â”€ app_yolo.py 
â”œâ”€â”€ app_mobilenet.py
â”œâ”€â”€ runs_MobilenetSSD_FPN_lite/
|   â””â”€â”€saved_model/
|   â””â”€â”€ detect.tflite 
|   â””â”€â”€ detect_quant.tflite
|   â””â”€â”€ edgetpu.tflite    
â”œâ”€â”€ runs_yolov5/
â”‚   â””â”€â”€ detect/
â”‚       â””â”€â”€ train/
â”‚           â””â”€â”€ weights/
â”‚               â”œâ”€â”€ best.pt
â”‚               â”œâ”€â”€ model_float32.tflite
â”‚               â”œâ”€â”€ model_int8_edgetpu.tflite
â”‚               â””â”€â”€ ...
â”œâ”€â”€ samples video test (.mp4)
```

---

## â–¶ï¸ How to Run

Run the main script:

```bash
cd Drowsy_detection/

streamlit run main_final.py
```

Opening a browser window at the IP address or localhost will display the webcam feed, along with real-time visual and audible alerts.

---

## ðŸ§  Alert Logic

- **Closed eyes** for 30 consecutive frames (Blink Ratio BR > 4.5) **and** YOLO detects `drowsy` âžœ Alert
- **Head leaning forward** (DSC > 1.2) for 30 frames **and** YOLO detects `drowsy` âžœ Alert
- YOLO detects `drowsy`, `phone`, or `smoking` for 30 frames âžœ Alert
- Any **combination of 2 or more active alerts at the same time** âžœ Triggers an audible alert once

---

## ðŸ“ˆ Performance

- **FPS** displayed in real-time in app streamlit 
- Compatible with **EdgeTPU** when a suitable `.tflite` model is loaded in `main.py`

---

## ðŸ“Œ Final Notes

- Ensure your YOLO model is trained for the expected classes: `drowsy`, `phone`, `smoking`, `seatbelt`, `awake`
- By default, the script uses the webcam (`cv2.VideoCapture(0)`) â€” modify this to load a video file if needed from the root directory

---
